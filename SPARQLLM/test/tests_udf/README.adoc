:toc:
:toclevels: 6
:source-highlighter: highlightjs
:icons: font
:sectnums:
:sectlinks:
:doctype: book

== Presentation

Nous avons réalisé les tests unitaires pour tous les fichiers présents dans le dossier UDF.

Nous avons classé les fichiers de test en deux groupes :

* **Tests avec mock**
    ** Nous avons regroupé les fichiers qui ne fonctionnaient pas directement lors de leur exécution dans un dossier nommé "test avec mock". Ces fichiers ont été testés à l’aide de mocks.

* **Tests sans mock**
    ** Les fichiers qui fonctionnaient parfaitement sans mock ont été placés dans un dossier intitulé "test sans mock".

Cependant, il y a deux exceptions à cette organisation : les fichiers **readfile.py et csv.py.** Bien que ces fichiers nécessitent des fichiers **HTML (pour readfile.py) et CSV (pour csv.py)**, nous avons choisi de les inclure dans le dossier "test avec mock". En effet, au lieu de créer plusieurs **fichiers HTML et CSV dans un répertoire pour nos tests, nous avons décidé d’utiliser des mocks directement dans les fichiers de test.**

Par ailleurs, nous avons dû modifier certains fichiers dans le dossier UDF afin de faire passer les tests.

== Comment exécuté les tests

=== Instalation des dépandances

Avant d'exécuter les tests et/ou les fichiers modifiés du dossier udf, **il est important avant tout d'installer les dépendances nécéssaires pour leur bon fonctionement:**

pour installer les dépendances de pour les **test et/ou des fichiers modifiés** il faut:

* d'abord se mettre à **la racine du projet** puis entrer la commande suivante:

[source,bash]
----
pip install --upgrade pip
pip install -r requirements.txt
----

* ensuite il faut **se rendre dans le dossier tests_udf** avec la commande :

[source,bash]
----
cd SPARQLLM/test/tests_udf/
----

* une fois a l'**interieur** du dossier tests_udf il faudra entrer les commandes suivantes:

[source,bash]
----
pip install -r tests_requirements.txt
pip install -r fichiersModifiees_requirements.txt
----


=== Execution des tests sans coverage

Commande pour lancer tous les tests: 
[source,python]
----
python -m unittest discover -s SPARQLLM/test/tests_udf 
----

Commande pour lancer un test spécifique:
[source,python]
----
python -m SPARQLLM.test.tests_udf.nom_dossier.nom_fichier
----

==== Fichier localisé dans test avec mock

par exemple si vous vous vouler exécuter le fichier test_funcSE.py qui est dans le répertoire de test avec mock vous devez entrer la commande suivante :

[source,python]
----
python -m SPARQLLM.test.tests_udf.test_with_mock.test_funcSE
----

==== Fichier localisé dans test sans mock

par exemple si vous vous vouler exécuter le fichier test_llmgraph.py qui est dans le répertoire de test sans mock vous devez entrer la commande suivante :

[source,python]
----
python -m SPARQLLM.test.tests_udf.test_without_mock.test_llmgraph
----

=== Execution des tests avec coverage
Package supplémentaire nécessaire pour exécuter le coverage:
[source,python]
----
pip install coverage
----

Puis exécuter:
[source,python]
----
coverage run -m unittest discover -s SPARQLLM/test/tests_udf
coverage report
coverage html
----

== En cas de soucis

=== si l'environement virtuel disparait et se fait remplacer par un autre lors de l'exécution de coverage run -m unittest discover -s SPARQLLM/test/tests_udf

il faut :

* supprimer le dossier **htmlcov** et le fichier **.coverage** à la racine du fichier

* En suite recommencer les instalations des dépendances du point **2.1**

=== si les test de fucLLM.py échoue lors de l'exécution de coverage run -m unittest discover -s SPARQLLM/test/tests_udf

Nous n'avons pas d'explications dû a cette érreur mais il peut arriver que quand on exécute la commande **coverage run -m unittest discover -s SPARQLLM/test/tests_udf**, les tests de la fonction funcLLM.py échouent alors qu'ils sont sensé passés.

si cela vous arrive, il faut juste relancer la commande **coverage run -m unittest discover -s SPARQLLM/test/tests_udf** jusqu'a ce que ça passe.